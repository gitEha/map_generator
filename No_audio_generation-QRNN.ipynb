{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, Input, concatenate, Dropout, SpatialDropout1D, Flatten, BatchNormalization, Conv1D, MaxPooling1D\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from clr_callback import CyclicLR\n",
    "from qrnn import QRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_DIR_PATH = 'MAPS/PROTOTYPE MAPS/'\n",
    "MAP_NAME = 'combined_maps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80,64,107\n",
      "128,192,380\n",
      "160,192,516\n",
      "176,320,789\n",
      "208,320,925\n",
      "232,192,1198\n",
      "264,192,1334\n",
      "288,320,1607\n",
      "320,320,1743\n",
      "336,192,2016\n"
     ]
    }
   ],
   "source": [
    "# Load the beatmap hitcirlces\n",
    "\n",
    "with open(os.path.join(MAP_DIR_PATH, MAP_NAME + '.txt')) as f:\n",
    "    content = [','.join(x.strip().split(',')[:3]) for x in f.readlines()]\n",
    "\n",
    "for i in range(10):\n",
    "    print(content[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 4284542\n",
      "80,64,107\n",
      "128,192,380\n",
      "160,192,516\n",
      "176,320,789\n",
      "208,320,925\n",
      "232,192,1198\n",
      "264,192,1334\n",
      "288,320,1607\n",
      "320,320,1743\n",
      "336,192,2016\n",
      "360,192,2152\n",
      "384,1\n",
      "------------\n",
      "0,64,107\n",
      "128,192,380\n",
      "160,192,516\n",
      "176,320,789\n",
      "208,320,925\n",
      "232,192,1198\n",
      "264,192,1334\n",
      "288,320,1607\n",
      "320,320,1743\n",
      "336,192,2016\n",
      "360,192,2152\n",
      "384,19\n",
      "------------\n",
      ",64,107\n",
      "128,192,380\n",
      "160,192,516\n",
      "176,320,789\n",
      "208,320,925\n",
      "232,192,1198\n",
      "264,192,1334\n",
      "288,320,1607\n",
      "320,320,1743\n",
      "336,192,2016\n",
      "360,192,2152\n",
      "384,192\n",
      "------------\n",
      "64,107\n",
      "128,192,380\n",
      "160,192,516\n",
      "176,320,789\n",
      "208,320,925\n",
      "232,192,1198\n",
      "264,192,1334\n",
      "288,320,1607\n",
      "320,320,1743\n",
      "336,192,2016\n",
      "360,192,2152\n",
      "384,192,\n",
      "------------\n",
      "4,107\n",
      "128,192,380\n",
      "160,192,516\n",
      "176,320,789\n",
      "208,320,925\n",
      "232,192,1198\n",
      "264,192,1334\n",
      "288,320,1607\n",
      "320,320,1743\n",
      "336,192,2016\n",
      "360,192,2152\n",
      "384,192,2\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "joined_maps = '\\n'.join(content)\n",
    "\n",
    "length = 140\n",
    "sequences = list()\n",
    "for i in range(length, len(joined_maps)):\n",
    "    # select sequence of tokens\n",
    "    seq = joined_maps[i-length:i+1]\n",
    "    # store\n",
    "    sequences.append(seq)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "\n",
    "for i in range(5):\n",
    "    print(sequences[i])\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 2, 1, 8, 6, 1, 3, 2, 9, 0, 3, 4, 10, 1, 3, 11, 4, 1, 5, 10, 2, 0, 3, 8, 2, 1, 3, 11, 4, 1, 7, 3, 8, 0, 3, 9, 8, 1, 5, 4, 2, 1, 9, 10, 11, 0, 4, 2, 10, 1, 5, 4, 2, 1, 11, 4, 7, 0, 4, 5, 4, 1, 3, 11, 4, 1, 3, 3, 11, 10, 0, 4, 8, 6, 1, 3, 11, 4, 1, 3, 5, 5, 6, 0, 4, 10, 10, 1, 5, 4, 2, 1, 3, 8, 2, 9, 0, 5, 4, 2, 1, 5, 4, 2, 1, 3, 9, 6, 5, 0, 5, 5, 8, 1, 3, 11, 4, 1, 4, 2, 3, 8, 0, 5, 8, 2, 1, 3, 11, 4, 1, 4, 3, 7, 4, 0, 5, 10, 6, 1, 3]\n",
      "------------\n",
      "[2, 1, 8, 6, 1, 3, 2, 9, 0, 3, 4, 10, 1, 3, 11, 4, 1, 5, 10, 2, 0, 3, 8, 2, 1, 3, 11, 4, 1, 7, 3, 8, 0, 3, 9, 8, 1, 5, 4, 2, 1, 9, 10, 11, 0, 4, 2, 10, 1, 5, 4, 2, 1, 11, 4, 7, 0, 4, 5, 4, 1, 3, 11, 4, 1, 3, 3, 11, 10, 0, 4, 8, 6, 1, 3, 11, 4, 1, 3, 5, 5, 6, 0, 4, 10, 10, 1, 5, 4, 2, 1, 3, 8, 2, 9, 0, 5, 4, 2, 1, 5, 4, 2, 1, 3, 9, 6, 5, 0, 5, 5, 8, 1, 3, 11, 4, 1, 4, 2, 3, 8, 0, 5, 8, 2, 1, 3, 11, 4, 1, 4, 3, 7, 4, 0, 5, 10, 6, 1, 3, 11]\n",
      "------------\n",
      "[1, 8, 6, 1, 3, 2, 9, 0, 3, 4, 10, 1, 3, 11, 4, 1, 5, 10, 2, 0, 3, 8, 2, 1, 3, 11, 4, 1, 7, 3, 8, 0, 3, 9, 8, 1, 5, 4, 2, 1, 9, 10, 11, 0, 4, 2, 10, 1, 5, 4, 2, 1, 11, 4, 7, 0, 4, 5, 4, 1, 3, 11, 4, 1, 3, 3, 11, 10, 0, 4, 8, 6, 1, 3, 11, 4, 1, 3, 5, 5, 6, 0, 4, 10, 10, 1, 5, 4, 2, 1, 3, 8, 2, 9, 0, 5, 4, 2, 1, 5, 4, 2, 1, 3, 9, 6, 5, 0, 5, 5, 8, 1, 3, 11, 4, 1, 4, 2, 3, 8, 0, 5, 8, 2, 1, 3, 11, 4, 1, 4, 3, 7, 4, 0, 5, 10, 6, 1, 3, 11, 4]\n",
      "------------\n",
      "[8, 6, 1, 3, 2, 9, 0, 3, 4, 10, 1, 3, 11, 4, 1, 5, 10, 2, 0, 3, 8, 2, 1, 3, 11, 4, 1, 7, 3, 8, 0, 3, 9, 8, 1, 5, 4, 2, 1, 9, 10, 11, 0, 4, 2, 10, 1, 5, 4, 2, 1, 11, 4, 7, 0, 4, 5, 4, 1, 3, 11, 4, 1, 3, 3, 11, 10, 0, 4, 8, 6, 1, 3, 11, 4, 1, 3, 5, 5, 6, 0, 4, 10, 10, 1, 5, 4, 2, 1, 3, 8, 2, 9, 0, 5, 4, 2, 1, 5, 4, 2, 1, 3, 9, 6, 5, 0, 5, 5, 8, 1, 3, 11, 4, 1, 4, 2, 3, 8, 0, 5, 8, 2, 1, 3, 11, 4, 1, 4, 3, 7, 4, 0, 5, 10, 6, 1, 3, 11, 4, 1]\n",
      "------------\n",
      "[6, 1, 3, 2, 9, 0, 3, 4, 10, 1, 3, 11, 4, 1, 5, 10, 2, 0, 3, 8, 2, 1, 3, 11, 4, 1, 7, 3, 8, 0, 3, 9, 8, 1, 5, 4, 2, 1, 9, 10, 11, 0, 4, 2, 10, 1, 5, 4, 2, 1, 11, 4, 7, 0, 4, 5, 4, 1, 3, 11, 4, 1, 3, 3, 11, 10, 0, 4, 8, 6, 1, 3, 11, 4, 1, 3, 5, 5, 6, 0, 4, 10, 10, 1, 5, 4, 2, 1, 3, 8, 2, 9, 0, 5, 4, 2, 1, 5, 4, 2, 1, 3, 9, 6, 5, 0, 5, 5, 8, 1, 3, 11, 4, 1, 4, 2, 3, 8, 0, 5, 8, 2, 1, 3, 11, 4, 1, 4, 3, 7, 4, 0, 5, 10, 6, 1, 3, 11, 4, 1, 4]\n",
      "------------\n",
      "Vocabulary Size: 15\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(joined_maps)))\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "sequences_mapped = list()\n",
    "for seq in sequences:\n",
    "    # integer encode line\n",
    "    encoded_seq = [mapping[char] for char in seq]\n",
    "    # store\n",
    "    sequences_mapped.append(encoded_seq)\n",
    "\n",
    "for i in range(5):\n",
    "    print(sequences_mapped[i])\n",
    "    print('------------')\n",
    "    \n",
    "\n",
    "\n",
    "# vocabulary size\n",
    "vocab_size = len(mapping)\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  8  6  1  3  2  9  0  3  4 10  1  3 11  4  1  5 10  2  0  3  8  2  1\n",
      "  3 11  4  1  7  3  8  0  3  9  8  1  5  4  2  1  9 10 11  0  4  2 10  1\n",
      "  5  4  2  1 11  4  7  0  4  5  4  1  3 11  4  1  3  3 11 10  0  4  8  6\n",
      "  1  3 11  4  1  3  5  5  6  0  4 10 10  1  5  4  2  1  3  8  2  9  0  5\n",
      "  4  2  1  5  4  2  1  3  9  6  5  0  5  5  8  1  3 11  4  1  4  2  3  8\n",
      "  0  5  8  2  1  3 11  4  1  4  3  7  4  0  5 10  6  1  3 11]\n",
      "4\n",
      "[ 1  8  6  1  3  2  9  0  3  4 10  1  3 11  4  1  5 10  2  0  3  8  2  1\n",
      "  3 11  4  1  7  3  8  0  3  9  8  1  5  4  2  1  9 10 11  0  4  2 10  1\n",
      "  5  4  2  1 11  4  7  0  4  5  4  1  3 11  4  1  3  3 11 10  0  4  8  6\n",
      "  1  3 11  4  1  3  5  5  6  0  4 10 10  1  5  4  2  1  3  8  2  9  0  5\n",
      "  4  2  1  5  4  2  1  3  9  6  5  0  5  5  8  1  3 11  4  1  4  2  3  8\n",
      "  0  5  8  2  1  3 11  4  1  4  3  7  4  0  5 10  6  1  3 11]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "sequences = np.array(sequences_mapped)\n",
    "X, y = sequences[:10000,:-1], sequences[:10000,-1]\n",
    "\n",
    "print(X[2])\n",
    "print(y[2])\n",
    "\n",
    "#X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "#sequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "#X = np.array(sequences)\n",
    "#y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "print(X[2])\n",
    "print(y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 140)\n",
      "(8000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 11:\n",
    "        lrate == 0.0001\n",
    "\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 140, 400)          6000      \n",
      "_________________________________________________________________\n",
      "qrnn_1 (QRNN)                (None, 140, 2500)         9007500   \n",
      "_________________________________________________________________\n",
      "qrnn_2 (QRNN)                (None, 140, 2500)         56257500  \n",
      "_________________________________________________________________\n",
      "qrnn_3 (QRNN)                (None, 140, 2500)         56257500  \n",
      "_________________________________________________________________\n",
      "qrnn_4 (QRNN)                (None, 2500)              56257500  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                37515     \n",
      "=================================================================\n",
      "Total params: 177,823,515\n",
      "Trainable params: 177,823,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 400, input_length=length))\n",
    "model.add(QRNN(2500, window_size=3, dropout=0.1, return_sequences=True))#, \n",
    "               #kernel_regularizer=l2(1e-4), bias_regularizer=l2(1e-4), \n",
    "               #kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10)))\n",
    "model.add(QRNN(2500, window_size=3, dropout=0.1, return_sequences=True))\n",
    "model.add(QRNN(2500, window_size=3, dropout=0.1, return_sequences=True))\n",
    "model.add(QRNN(2500, window_size=3, dropout=0.1))\n",
    "\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1000\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,1,2500,7500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/mul_38 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam_1/beta_2/read, training_1/Adam/Variable_18/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_1/Adam/gradients/loss_1/dense_1_loss/clip_by_value/Minimum_grad/Reshape/_281 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1722_...ad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training_1/Adam/mul_38', defined at:\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-a13cb9b8139f>\", line 6, in <module>\n    validation_data=(X_val, y_val), verbose=1, callbacks=[lrate])\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\keras\\models.py\", line 963, in fit\n    validation_steps=validation_steps)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1689, in fit\n    self._make_train_function()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py\", line 462, in get_updates\n    v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 780, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 934, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1161, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 3091, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,1,2500,7500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/mul_38 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam_1/beta_2/read, training_1/Adam/Variable_18/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_1/Adam/gradients/loss_1/dense_1_loss/clip_by_value/Minimum_grad/Reshape/_281 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1722_...ad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,1,2500,7500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/mul_38 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam_1/beta_2/read, training_1/Adam/Variable_18/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_1/Adam/gradients/loss_1/dense_1_loss/clip_by_value/Minimum_grad/Reshape/_281 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1722_...ad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a13cb9b8139f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model.fit(X_train, y_train, batch_size=15, epochs=1000,\n\u001b[1;32m----> 6\u001b[1;33m            validation_data=(X_val, y_val), verbose=1, callbacks=[lrate])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1712\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,1,2500,7500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/mul_38 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam_1/beta_2/read, training_1/Adam/Variable_18/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_1/Adam/gradients/loss_1/dense_1_loss/clip_by_value/Minimum_grad/Reshape/_281 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1722_...ad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training_1/Adam/mul_38', defined at:\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-a13cb9b8139f>\", line 6, in <module>\n    validation_data=(X_val, y_val), verbose=1, callbacks=[lrate])\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\keras\\models.py\", line 963, in fit\n    validation_steps=validation_steps)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1689, in fit\n    self._make_train_function()\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py\", line 462, in get_updates\n    v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 780, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 934, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1161, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 3091, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,1,2500,7500] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/mul_38 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Adam_1/beta_2/read, training_1/Adam/Variable_18/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: training_1/Adam/gradients/loss_1/dense_1_loss/clip_by_value/Minimum_grad/Reshape/_281 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1722_...ad/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "#clr = CyclicLR(base_lr=0.001, max_lr=0.006, step_size=2000.)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X_train, y_train, batch_size=15, epochs=1000,\n",
    "           validation_data=(X_val, y_val), verbose=1, callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.optimizer.lr)\n",
    "import keras.backend as K\n",
    "\n",
    "K.set_value(model.optimizer.lr, 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('MODEL/no_music_test_weights_2.h5')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=512, epochs=10,\n",
    "           validation_data=(X_val, y_val), verbose=1)#, callbacks=[clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('MODEL/no_music_test_model_embedding.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MODEL/no_music_test_model_embedding.h5')\n",
    "model.save_weights('MODEL/no_music_test_weights_embedding.h5')\n",
    "np.save('MODEL/no_music_test_embedding.np', model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of characters\n",
    "    for _ in range(n_chars):\n",
    "        # encode the characters as integers\n",
    "        encoded = [mapping[char] for char in in_text]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        #encoded = encoded.reshape(encoded.shape[0], encoded.shape[1], 1)\n",
    "        # one hot encode\n",
    "       # encoded = encoded, num_classes=len(mapping)\n",
    "        # predict character\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # reverse map integer to character\n",
    "        out_char = ''\n",
    "        for char, index in mapping.items():\n",
    "            if index == yhat:\n",
    "                out_char = char\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += char\n",
    "    return in_text\n",
    "\n",
    "\n",
    "seed_text = '''\n",
    "317,197,281\n",
    "256,241,612\n",
    "357,346,778\n",
    "396,208,944\n",
    "336,268,1109\n",
    "195,197,1275\n",
    "258,0,1607\n",
    "374,80,1773\n",
    "256,149,1938\n",
    "292,74,2104\n",
    "180,103,2270\n",
    "101,259,2601\n",
    "40,194,2933\n",
    "203,238,3099\n",
    "126,350,3265\n",
    "298,265,3596\n",
    "255,322,3928\n",
    "336,200,4093\n",
    "'''\n",
    "\n",
    "print(generate_seq(model, mapping, length, seed_text, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
