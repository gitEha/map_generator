{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, Input, concatenate, Dropout, SpatialDropout1D, Flatten, BatchNormalization, Conv1D, MaxPooling1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_DIR_PATH = 'MAPS/PROTOTYPE MAPS/'\n",
    "MAP_NAME = 'combined_maps.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80,64,107,1,0\n",
      "128,192,380,5,0\n",
      "160,192,516,1,0\n",
      "176,320,789,1,0\n",
      "208,320,925,1,0\n",
      "232,192,1198,1,0\n",
      "264,192,1334,1,0\n",
      "288,320,1607,1,0\n",
      "320,320,1743,1,0\n",
      "336,192,2016,1,0\n"
     ]
    }
   ],
   "source": [
    "# Load the beatmap hitcirlces\n",
    "\n",
    "with open(os.path.join(MAP_DIR_PATH, MAP_NAME + '.osu')) as f:\n",
    "    content = [x.strip() for x in f.readlines()]\n",
    "\n",
    "hitobjects_index = [x for x in content].index('[HitObjects]')\n",
    "hitobjects = [x.split(',')[:3] for x in content[hitobjects_index + 1:]]\n",
    "\n",
    "for i in range(10):\n",
    "    print(hitobjects[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hitobjects' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-739936f0d34c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Preprocesses the labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhitobjects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# X and y cordinate labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtime_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hitobjects' is not defined"
     ]
    }
   ],
   "source": [
    "# Preprocesses the labels\n",
    "\n",
    "print(len(hitobjects))\n",
    "# X and y cordinate labels\n",
    "time_values = []\n",
    "y_x = []\n",
    "y_y = []\n",
    "\n",
    "map_start = int(hitobjects[0][-1])\n",
    "\n",
    "for y in hitobjects:\n",
    "    y_x.append(y[0])\n",
    "    y_y.append(y[1])\n",
    "    time_values.append(int(y[-1]))\n",
    "    \n",
    "print('Time_values:', time_values[1], 'x:', y_x[1], 'y:', y_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before:  100127\n",
      "Length after:  78405\n",
      "Length of samples in one timestep:  88\n"
     ]
    }
   ],
   "source": [
    "# Load the song\n",
    "\n",
    "map_song = AudioSegment.from_file(os.path.join(MAP_DIR_PATH, MAP_NAME + '.mp3'), format='mp3')\n",
    "\n",
    "print('Length before: ', len(map_song))\n",
    "song_in_map_range = map_song[map_start:int(hitobjects[-1][-1])]\n",
    "print('Length after: ', len(song_in_map_range))\n",
    "\n",
    "print('Length of samples in one timestep: ', len(song_in_map_range[0].get_array_of_samples()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nan', 'nan']\n",
      "['nan', 'nan']\n",
      "Total timing matches 156 out of 78405\n",
      "Len of X: 78405 \n",
      "example values: [ -174  9910  2588 10408  5989]\n",
      "\n",
      "\n",
      "X and y pairs: \n",
      "X: [ -174  9910  2588 10408  5989] \n",
      "y: ['nan', 'nan']\n"
     ]
    }
   ],
   "source": [
    "OUTPUTS_PER_SECOND = 20\n",
    "INPUTS_PER_TIMESTEP = 250\n",
    "\n",
    "# Loop over each second of the song and get the data and labels for timesteps\n",
    "# loop over the song ms by ms, if ms has hitcircle on it, append 1(coordinates included) else 0 (coordinates not included)\n",
    "X = []\n",
    "y = []\n",
    "timing_matches = 0\n",
    "for i in range(0,  len(song_in_map_range)):\n",
    "    X.append(np.asarray(song_in_map_range[i].get_array_of_samples()))\n",
    "    if i in time_values:\n",
    "        y.append([y_x[timing_matches], y_y[timing_matches]])\n",
    "        timing_matches += 1\n",
    "    else:\n",
    "        y.append(['nan', 'nan'])\n",
    "    \n",
    "\n",
    "        \n",
    "print(y[0])\n",
    "print(y[1])\n",
    "print('Total timing matches', len([i for i in y if i[0] != 'nan']), 'out of', len(y))\n",
    "print('Len of X:', len(X), '\\nexample values:', X[0][0:5])\n",
    "\n",
    "print('\\n\\nX and y pairs:', '\\nX:', X[0][0:5], '\\ny:', y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of X: 233 \n",
      "amount of examples: 2000\n"
     ]
    }
   ],
   "source": [
    "# Loop over the hitcircles and get audio data from 1 second before and 1 second after the hitcirclec \n",
    "# loop over the song ms by ms, if ms has hitcircle on it, append 1(coordinates included) else 0 (coordinates not included)\n",
    "X = []\n",
    "timing_matches = 0\n",
    "\n",
    "for i, y in enumerate(time_values):\n",
    "    X.append([])\n",
    "    for j in range(-1000, 0):        \n",
    "        X[i].append(map_song[y + j].get_array_of_samples().tolist())\n",
    "        \n",
    "    for j in range(1000):\n",
    "        X[i].append(map_song[y + j].get_array_of_samples().tolist())\n",
    "        \n",
    "\n",
    "print('Len of X:', len(X), '\\namount of examples:', len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array min: -17411 array max: 18648\n",
      "Divider: 3.7296\n",
      "Before: [ -174  9910  2588 10408  5989 13656  7966 14921  3180  8682]\n",
      "After: [ -47. 2657.  693. 2790. 1605. 3661. 2135. 4000.  852. 2327.]\n",
      "Max: 4999.0\n",
      "Min: -4669.0\n"
     ]
    }
   ],
   "source": [
    "# Reduce X dimensionality\n",
    "array_min = min(X[0])\n",
    "array_max = max(X[0])\n",
    "\n",
    "maxval = 5000 # HYPERPARAMETER to reduce dimensionality\n",
    "\n",
    "print('Array min:',array_min, 'array max:',array_max)\n",
    "\n",
    "divider = array_max / maxval\n",
    "print('Divider:', divider)\n",
    "\n",
    "print('Before:', X[0][0:10])\n",
    "print('After:',X[0][0:10] // divider)\n",
    "\n",
    "print('Max:',max(X[0] // divider))\n",
    "print('Min:',min(X[0] // divider))\n",
    "\n",
    "X = X // divider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for the classifier:\n",
    "\n",
    "Turn coordinate values into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-47 2657 693 2790 1605 3661 2135 4000 852 2327 -1193 504 -554 1387 2179 3177 2645 1942 199 -1511 -17\n",
      "-823 -815 -798 -554 -573 -408 -217 -275 25 -185 105 -467 382 -742 676 -790 756 -839 902 -729 786 -61\n",
      "nannan\n",
      "nannan\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stringified_X = []\n",
    "for ind, x in enumerate(X):\n",
    "    listed_str = []\n",
    "    \n",
    "    for i in x:        \n",
    "        listed_str.append(str(int(i)))\n",
    "    stringified_X.append(' '.join(listed_str))\n",
    "\n",
    "stringified_y = [''.join(i) for i in y] # should be ' '.join\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(stringified_X, stringified_y, test_size=0.25, shuffle=False)\n",
    "\n",
    "# turn coordinate values into a big string\n",
    "print(X_train[0][0:100])\n",
    "print(X_val[0][0:100])\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True vocab size: 128\n",
      "Before: nannan\n",
      "After: [1]\n",
      "Before: nannan\n",
      "After: [1]\n",
      "True vocab size: 8786\n",
      "Before: -823 -815 -798 -554 -573 -408 -217 -275 25 -185 105 -467 382 -742 676 -790 756 -839 902 -729 786 -610 109 -731 -337 -582 -224 -183 -153 -207 -263 -422 -254 -387 -112 -447 -39 -737 -112 -909 -105 -872 118 -697 223 -451 39 -269 -40 -57 163 247 324 345 415 230 683 162 1041 118 1277 197 1258 396 941 338 688 245 685 482 489 544 42 236 -172 75 -42 151 243 252 497 245 621 96 818 102 1065 236\n",
      "After: [ 608  545  972  718  758  255   56   95  412  563  128  243  217  670\n",
      "  761  439  483 1082 1088  883  555  751  111  361  582  262  130  119\n",
      "  120  417  527  667   31  166  108  479   52  510  108  992  128 1112\n",
      "  458  485   75  700   52  468  427   78  392  517  182   83  601  552\n",
      "  475  543  769  458 1107  385 1380  386  733   91  940  441  804  219\n",
      "  661  710   29  440   27   73   29  532  160  398  190  441  825  461\n",
      "  936    8 1309  440]\n",
      "Before: -47 2657 693 2790 1605 3661 2135 4000 852 2327 -1193 504 -554 1387 2179 3177 2645 1942 199 -1511 -1776 -2802 -1917 -977 -1691 339 -1662 -568 -707 -553 1018 1709 1341 2230 -162 -613 -1183 -3036 -941 -3377 -1106 -3900 -1681 -4669 -706 -3426 848 -1338 -68 -1817 -1889 -3739 -799 -3316 2195 -824 4466 1315 4999 1747 2567 -252 -578 -2211 -110 -1015 2176 1243 2535 2194 1654 2689 712 2419 487 1648 1725 2307 2492 3611 1387 3751 -495 2412 -2574 67 -3720 -946\n",
      "After: [   6 2343  299 2668 1778 3763 1925 3743  581 2325  942  209  718 1490\n",
      " 2300 3442 2825 2010  282 1334 1911 2590 1757  983 1839   89 1593  278\n",
      "  902  134 1178 1878 1161 2417  543  731 1322 3459  733 3550 1183 3591\n",
      " 1526 4397  794 3228  599 1564   90 1644 2145 3909 1005 2916 2129  962\n",
      " 4261  998 4698 1577 2739  398  256 2443  480  964 2091 1371 2202 2302\n",
      " 1920 2745  298 2533  189 1560 1513 2574 2640 3381 1490 3674  656 2515\n",
      " 2701  442 3806 1111]\n"
     ]
    }
   ],
   "source": [
    "label_vocab_size = 1500 # Don't really need more than 1000, but for some reason a bigger vocab_size is good for the tokenizer\n",
    "label_seq_len = 2\n",
    "\n",
    "feature_vocab_size = 15000\n",
    "feature_seq_len = 88\n",
    "\n",
    "def tokenization_processing(x_to_tok, x_val_to_tok, vocab_size=1500, seq_len=2, pad=False):\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=vocab_size,\n",
    "                                       filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                       split=\" \",\n",
    "                                       char_level=False, # Could be very very interesting\n",
    "                                       oov_token=None)\n",
    "\n",
    "    tokenizer.fit_on_texts(x_val_to_tok + x_to_tok)\n",
    "    print('True vocab size:', len(tokenizer.word_index))\n",
    "    \n",
    "    X_tokenized = tokenizer.texts_to_sequences(x_to_tok)\n",
    "    X_val_tokenized = tokenizer.texts_to_sequences(x_val_to_tok)\n",
    "    \n",
    "    if pad:\n",
    "        X_tokenized = pad_sequences(X_tokenized, maxlen=seq_len)\n",
    "        X_val_tokenized = pad_sequences(X_val_tokenized, maxlen=seq_len)\n",
    "    \n",
    "    print('Before:', x_val_to_tok[0])\n",
    "    print('After:', X_val_tokenized[0])\n",
    "    print('Before:', x_to_tok[0])\n",
    "    print('After:',X_tokenized[0])\n",
    "    \n",
    "    return [X_tokenized, X_val_tokenized, tokenizer]\n",
    "\n",
    "Y_tokenized, y_val_tokenized, tokenizer_y = tokenization_processing(y_train, y_val)\n",
    "X_train_tokenized, X_val_tokenized, tokenizer_x = tokenization_processing(X_train, X_val, vocab_size=feature_vocab_size, seq_len=feature_seq_len, pad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58803\n",
      "58803\n",
      "230\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_tokenized))\n",
    "print(len(X_train_tokenized))\n",
    "\n",
    "\n",
    "def create_mini_batches(input_X, input_y, batch_size):\n",
    "    batched_X = []\n",
    "    batched_y = []\n",
    "    for i in range(int(len(input_X) / batch_size) + 1):\n",
    "        batched_X.append(input_X[i*batch_size:i*batch_size + batch_size])\n",
    "        batched_y.append(input_y[i*batch_size:i*batch_size + batch_size])\n",
    "\n",
    "    return (batched_X, batched_y)\n",
    "\n",
    "X_train_timestepped, y_train_timestepped = create_mini_batches(X_train_tokenized, Y_tokenized, 256)\n",
    "X_val_timestepped, y_val_timestepped = create_mini_batches(X_val_tokenized, y_val_tokenized, 256)\n",
    "\n",
    "print(len(X_train_timestepped))\n",
    "print(len(X_val_timestepped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 88, 10)            150000    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1500)              76500     \n",
      "=================================================================\n",
      "Total params: 238,700\n",
      "Trainable params: 238,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(feature_vocab_size, 10, input_length=feature_seq_len))\n",
    "model.add(LSTM(50))\n",
    "#model.add(LSTM(50))\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(label_vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0, 1: 1e-06, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0, 20: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 24: 1.0, 25: 1.0, 26: 1.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 1.0, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 1.0, 51: 1.0, 52: 1.0, 53: 1.0, 54: 1.0, 55: 1.0, 56: 1.0, 57: 1.0, 58: 1.0, 59: 1.0, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 1.0, 67: 1.0, 68: 1.0, 69: 1.0, 70: 1.0, 71: 1.0, 72: 1.0, 73: 1.0, 74: 1.0, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 1.0, 81: 1.0, 82: 1.0, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 1.0, 88: 1.0, 89: 1.0, 90: 1.0, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 1.0, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 1.0, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 1.0, 159: 1.0, 160: 1.0, 161: 1.0, 162: 1.0, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 1.0, 169: 1.0, 170: 1.0, 171: 1.0, 172: 1.0, 173: 1.0, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 1.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0}\n",
      "Train on 58803 samples, validate on 19602 samples\n",
      "Epoch 1/100\n",
      "58803/58803 [==============================] - 222s 4ms/step - loss: 0.0145 - acc: 0.0063 - val_loss: 6.6531 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0111 - acc: 1.7006e-05 - val_loss: 6.9922 - val_acc: 5.1015e-05\n",
      "Epoch 3/100\n",
      "58803/58803 [==============================] - 220s 4ms/step - loss: 0.0097 - acc: 1.7006e-05 - val_loss: 7.1415 - val_acc: 5.1015e-05\n",
      "Epoch 4/100\n",
      "58803/58803 [==============================] - 218s 4ms/step - loss: 0.0091 - acc: 5.1018e-05 - val_loss: 7.4132 - val_acc: 5.1015e-05\n",
      "Epoch 5/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0084 - acc: 8.5030e-05 - val_loss: 7.3024 - val_acc: 5.1015e-05\n",
      "Epoch 6/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0079 - acc: 3.4012e-05 - val_loss: 6.8689 - val_acc: 5.1015e-05\n",
      "Epoch 7/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0074 - acc: 1.0204e-04 - val_loss: 6.5944 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0069 - acc: 1.1904e-04 - val_loss: 5.4902 - val_acc: 5.1015e-05\n",
      "Epoch 9/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0063 - acc: 2.0407e-04 - val_loss: 5.1459 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0056 - acc: 4.4215e-04 - val_loss: 5.3110 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0051 - acc: 5.2718e-04 - val_loss: 5.0805 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0046 - acc: 0.0011 - val_loss: 4.1083 - val_acc: 0.0043\n",
      "Epoch 13/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0040 - acc: 0.0048 - val_loss: 5.3470 - val_acc: 9.1827e-04\n",
      "Epoch 14/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0035 - acc: 0.0015 - val_loss: 5.3856 - val_acc: 2.0406e-04\n",
      "Epoch 15/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0030 - acc: 0.0045 - val_loss: 4.6068 - val_acc: 0.0160\n",
      "Epoch 16/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0026 - acc: 0.0392 - val_loss: 4.7505 - val_acc: 0.0044\n",
      "Epoch 17/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0022 - acc: 0.0041 - val_loss: 4.7779 - val_acc: 0.0086\n",
      "Epoch 18/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0017 - acc: 0.0058 - val_loss: 5.2181 - val_acc: 0.0026\n",
      "Epoch 19/100\n",
      "58803/58803 [==============================] - 220s 4ms/step - loss: 0.0015 - acc: 0.0218 - val_loss: 4.3610 - val_acc: 0.0237\n",
      "Epoch 20/100\n",
      "58803/58803 [==============================] - 220s 4ms/step - loss: 0.0012 - acc: 0.0313 - val_loss: 4.2267 - val_acc: 0.0336\n",
      "Epoch 21/100\n",
      "58803/58803 [==============================] - 219s 4ms/step - loss: 0.0011 - acc: 0.0630 - val_loss: 5.0986 - val_acc: 0.0035\n",
      "Epoch 22/100\n",
      "58803/58803 [==============================] - 220s 4ms/step - loss: 7.2822e-04 - acc: 0.0693 - val_loss: 3.0369 - val_acc: 0.2236\n",
      "Epoch 23/100\n",
      "58803/58803 [==============================] - 220s 4ms/step - loss: 5.0193e-04 - acc: 0.2268 - val_loss: 3.9631 - val_acc: 0.1092\n",
      "Epoch 24/100\n",
      "58803/58803 [==============================] - 221s 4ms/step - loss: 4.5385e-04 - acc: 0.1103 - val_loss: 3.8013 - val_acc: 0.1047\n",
      "Epoch 25/100\n",
      "58803/58803 [==============================] - 221s 4ms/step - loss: 3.8338e-04 - acc: 0.1866 - val_loss: 3.9991 - val_acc: 0.0628\n",
      "Epoch 26/100\n",
      "58803/58803 [==============================] - 221s 4ms/step - loss: 4.7724e-04 - acc: 0.0518 - val_loss: 3.4455 - val_acc: 0.1441\n",
      "Epoch 27/100\n",
      "58803/58803 [==============================] - 221s 4ms/step - loss: 2.5648e-04 - acc: 0.1789 - val_loss: 2.2819 - val_acc: 0.4100\n",
      "Epoch 28/100\n",
      "58803/58803 [==============================] - 222s 4ms/step - loss: 1.3830e-04 - acc: 0.4068 - val_loss: 2.2384 - val_acc: 0.4149\n",
      "Epoch 29/100\n",
      "58803/58803 [==============================] - 224s 4ms/step - loss: 9.0746e-05 - acc: 0.5268 - val_loss: 1.3067 - val_acc: 0.6629\n",
      "Epoch 30/100\n",
      "58803/58803 [==============================] - 227s 4ms/step - loss: 5.6125e-05 - acc: 0.6049 - val_loss: 1.9282 - val_acc: 0.4954\n",
      "Epoch 31/100\n",
      "58803/58803 [==============================] - 227s 4ms/step - loss: 8.0144e-05 - acc: 0.4328 - val_loss: 2.0572 - val_acc: 0.4697\n",
      "Epoch 32/100\n",
      "58803/58803 [==============================] - 228s 4ms/step - loss: 8.9086e-05 - acc: 0.4518 - val_loss: 1.4837 - val_acc: 0.6227\n",
      "Epoch 33/100\n",
      "18816/58803 [========>.....................] - ETA: 2:26 - loss: 8.7077e-05 - acc: 0.5457"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-36e40c47feaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0.000001\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tokenized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_tokenized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_tokenized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val_tokenized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1712\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.fit(np.asarray(X_train_timestepped), np.asarray(y_train_timestepped), epochs=5, verbose=1, batch_size=32, validation_data=(np.asarray(X_val_timestepped), np.asarray(y_val_timestepped)))\n",
    "class_weight = {y: 1. if y != 1 else 0.000001 for y in range(200)}\n",
    "print(class_weight)\n",
    "model.fit(np.asarray(X_train_tokenized), np.asarray(Y_tokenized), class_weight=class_weight, epochs=100, verbose=1, batch_size=32, validation_data=(np.asarray(X_val_tokenized), np.asarray(y_val_tokenized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MODEL/33_epochs_music.h5')\n",
    "model.save_weights('MODEL/33_epochs_music_weights.h5')\n",
    "np.save('MODEL/33_epochs_music_weights.np', model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[16]\n",
      "[83]\n",
      "[18]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[105]\n",
      "[16]\n",
      "[110]\n",
      "-823 -815 -798 -554 -573 -408 -217 -275 25 -185 105 -467 382 -742 676 -790 756 -839 902 -729 786 -610 109 -731 -337 -582 -224 -183 -153 -207 -263 -422 -254 -387 -112 -447 -39 -737 -112 -909 -105 -872 118 -697 223 -451 39 -269 -40 -57 163 247 324 345 415 230 683 162 1041 118 1277 197 1258 396 941 338 688 245 685 482 489 544 42 236 -172 75 -42 151 243 252 497 245 621 96 818 102 1065 236 135 158 345 94 2 2 2 2 158 6\n"
     ]
    }
   ],
   "source": [
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words, sequence_len=feature_seq_len):\n",
    "    end_text = seed_text\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = np.array(tokenizer.texts_to_sequences([in_text]))        \n",
    "        if(encoded.shape != (1, sequence_len)):\n",
    "            encoded = np.array([np.append(encoded[0], 0)])\n",
    "        # pre-pad sequences to a fixed length\n",
    "        #encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        print(yhat)     \n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "            elif yhat==[0]:\n",
    "                out_word = '.'\n",
    "                end_text += ' ' + out_word\n",
    "                return end_text\n",
    "        # append to input\n",
    "        end_text += ' ' + out_word\n",
    "        in_text = in_text.split(' ')[1:]\n",
    "        in_text.append(out_word)\n",
    "        in_text = ' '.join(in_text)        \n",
    "        \n",
    "    return end_text\n",
    "\n",
    "print(generate_seq(model, tokenizer_x, feature_seq_len-1, '-823 -815 -798 -554 -573 -408 -217 -275 25 -185 105 -467 382 -742 676 -790 756 -839 902 -729 786 -610 109 -731 -337 -582 -224 -183 -153 -207 -263 -422 -254 -387 -112 -447 -39 -737 -112 -909 -105 -872 118 -697 223 -451 39 -269 -40 -57 163 247 324 345 415 230 683 162 1041 118 1277 197 1258 396 941 338 688 245 685 482 489 544 42 236 -172 75 -42 151 243 252 497 245 621 96 818 102 1065 236', 10, sequence_len=feature_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('256192', 2)\n",
      "('256344', 17)\n",
      "('216272', 84)\n",
      "('192243', 19)\n",
      "('352240', 106)\n",
      "('352240', 106)\n",
      "('352240', 106)\n",
      "('352240', 106)\n",
      "('256344', 17)\n",
      "('25648', 111)\n"
     ]
    }
   ],
   "source": [
    "print(list(tokenizer_y.word_index.items())[1])\n",
    "print(list(tokenizer_y.word_index.items())[16])\n",
    "print(list(tokenizer_y.word_index.items())[83])\n",
    "print(list(tokenizer_y.word_index.items())[18])\n",
    "print(list(tokenizer_y.word_index.items())[105])\n",
    "print(list(tokenizer_y.word_index.items())[105])\n",
    "print(list(tokenizer_y.word_index.items())[105])\n",
    "print(list(tokenizer_y.word_index.items())[105])\n",
    "print(list(tokenizer_y.word_index.items())[16])\n",
    "print(list(tokenizer_y.word_index.items())[110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the song (X):  79\n",
      "Length of one second:  250\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the audio data\n",
    "\n",
    "OUTPUTS_PER_SECOND = 20\n",
    "INPUTS_PER_TIMESTEP = 250\n",
    "\n",
    "# Loop over each second of the song and get the audio data for timesteps\n",
    "X = []\n",
    "for ind, i in enumerate(range(0,  len(song_in_map_range), 1000)):\n",
    "    X.append([])\n",
    "    \n",
    "    # Step in timestep frequency, eg 4\n",
    "    for j in range(0, len(song_in_map_range[i:i+1000]), 1000//INPUTS_PER_TIMESTEP):\n",
    "        X[ind].append(song_in_map_range[j].get_array_of_samples())\n",
    "        \n",
    "    # This doesn't work because of the slicing step:\n",
    "    #X.append(song_in_map_range[i:i+1000:1000//INPUTS_PER_TIMESTEP])            \n",
    "    \n",
    "\n",
    "print('Length of the song (X): ', len(X))\n",
    "print('Length of one second: ', len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
