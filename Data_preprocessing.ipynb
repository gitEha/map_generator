{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranet\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, Input, concatenate, Dropout, SpatialDropout1D, Flatten, BatchNormalization, Conv1D, MaxPooling1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_DIR_PATH = 'MAPS\\\\PROTOTYPE MAPS\\\\'\n",
    "MAP_NAME = 'Levels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['376', '307', '14036']\n",
      "['176', '192', '14888']\n",
      "['336', '192', '15101']\n",
      "['200', '248', '15314']\n",
      "['312', '136', '15527']\n",
      "['256', '272', '15741']\n",
      "['256', '112', '15954']\n",
      "['312', '248', '16167']\n",
      "['200', '136', '16380']\n",
      "['56', '56', '16806']\n"
     ]
    }
   ],
   "source": [
    "# Load the beatmap hitcirlces\n",
    "\n",
    "with open(os.path.join(MAP_DIR_PATH, MAP_NAME + '.osu')) as f:\n",
    "    content = [x.strip() for x in f.readlines()]\n",
    "\n",
    "hitobjects_index = [x for x in content].index('[HitObjects]')\n",
    "hitobjects = [x.split(',')[:3] for x in content[hitobjects_index + 1:]]\n",
    "\n",
    "for i in range(10):\n",
    "    print(hitobjects[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n",
      "Time_values: 852 x: 176 y: 192\n"
     ]
    }
   ],
   "source": [
    "# Preprocesses the labels\n",
    "\n",
    "print(len(hitobjects))\n",
    "# X and y cordinate labels\n",
    "time_values = []\n",
    "y_x = []\n",
    "y_y = []\n",
    "\n",
    "map_start = int(hitobjects[0][-1])\n",
    "\n",
    "for y in hitobjects:\n",
    "    y_x.append(y[0])\n",
    "    y_y.append(y[1])\n",
    "    time_values.append(int(y[-1]) - map_start)\n",
    "    \n",
    "print('Time_values:', time_values[1], 'x:', y_x[1], 'y:', y_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before:  100127\n",
      "Length after:  78405\n",
      "Length of samples in one timestep:  88\n"
     ]
    }
   ],
   "source": [
    "# Load the song\n",
    "\n",
    "map_song = AudioSegment.from_file(os.path.join(MAP_DIR_PATH, MAP_NAME + '.mp3'), format='mp3')\n",
    "\n",
    "print('Length before: ', len(map_song))\n",
    "song_in_map_range = map_song[map_start:int(hitobjects[-1][-1])]\n",
    "print('Length after: ', len(song_in_map_range))\n",
    "\n",
    "print('Length of samples in one timestep: ', len(song_in_map_range[0].get_array_of_samples()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['376', '307']\n",
      "['nan', 'nan']\n",
      "Total timing matches 232 out of 78405\n",
      "Len of X: 78405 \n",
      "example values: [ -174  9910  2588 10408  5989]\n",
      "\n",
      "\n",
      "X and y pairs: \n",
      "X: [ -174  9910  2588 10408  5989] \n",
      "y: ['376', '307']\n"
     ]
    }
   ],
   "source": [
    "OUTPUTS_PER_SECOND = 20\n",
    "INPUTS_PER_TIMESTEP = 250\n",
    "\n",
    "# Loop over each second of the song and get the data and labels for timesteps\n",
    "# loop over the song ms by ms, if ms has hitcircle on it, append 1(coordinates included) else 0 (coordinates not included)\n",
    "X = []\n",
    "y = []\n",
    "timing_matches = 0\n",
    "for i in range(0,  len(song_in_map_range)):\n",
    "    X.append(np.asarray(song_in_map_range[i].get_array_of_samples()))\n",
    "    if i in time_values:\n",
    "        y.append([y_x[timing_matches], y_y[timing_matches]])\n",
    "        timing_matches += 1\n",
    "    else:\n",
    "        y.append(['nan', 'nan'])\n",
    "    \n",
    "\n",
    "        \n",
    "print(y[0])\n",
    "print(y[1])\n",
    "print('Total timing matches', len([i for i in y if i[0] != 'nan']), 'out of', len(y))\n",
    "print('Len of X:', len(X), '\\nexample values:', X[0][0:5])\n",
    "\n",
    "print('\\n\\nX and y pairs:', '\\nX:', X[0][0:5], '\\ny:', y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array min: -17411 array max: 18648\n",
      "Divider: 3.7296\n",
      "Before: [ -174  9910  2588 10408  5989 13656  7966 14921  3180  8682]\n",
      "After: [ -47. 2657.  693. 2790. 1605. 3661. 2135. 4000.  852. 2327.]\n",
      "Max: 4999.0\n",
      "Min: -4669.0\n"
     ]
    }
   ],
   "source": [
    "# Reduce X dimensionality\n",
    "array_min = min(X[0])\n",
    "array_max = max(X[0])\n",
    "\n",
    "maxval = 5000 # HYPERPARAMETER to reduce dimensionality\n",
    "\n",
    "print('Array min:',array_min, 'array max:',array_max)\n",
    "\n",
    "divider = array_max / maxval\n",
    "print('Divider:', divider)\n",
    "\n",
    "print('Before:', X[0][0:10])\n",
    "print('After:',X[0][0:10] // divider)\n",
    "\n",
    "print('Max:',max(X[0] // divider))\n",
    "print('Min:',min(X[0] // divider))\n",
    "\n",
    "X = X // divider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for the classifier:\n",
    "\n",
    "Turn coordinate values into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['376 307', 'nan nan', 'nan nan', 'nan nan', 'nan nan', 'nan nan', 'nan nan', 'nan nan', 'nan nan', 'nan nan']\n",
      "['nan nan', '144 192', 'nan nan', 'nan nan', 'nan nan', 'nan nan', 'nan nan', 'nan nan', 'nan nan', 'nan nan']\n",
      "-47 2657 693 2790 1605 3661 2135 4000 852 2327 -1193 504 -554 1387 2179 3177 2645 1942 199 -1511 -17\n",
      "-823 -815 -798 -554 -573 -408 -217 -275 25 -185 105 -467 382 -742 676 -790 756 -839 902 -729 786 -61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stringified_X = []\n",
    "for ind, x in enumerate(X):\n",
    "    listed_str = []\n",
    "    \n",
    "    for i in x:        \n",
    "        listed_str.append(str(int(i)))\n",
    "    stringified_X.append(' '.join(listed_str))\n",
    "\n",
    "stringified_y = [' '.join(i) for i in y]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(stringified_X, stringified_y, test_size=0.25, shuffle=False)\n",
    "\n",
    "# turn coordinate values into a big string\n",
    "print(stringified_y[0:10])\n",
    "print(stringified_y_val[0:10])\n",
    "print(X_train[0][0:100])\n",
    "print(X_val[0][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True vocab size: 179\n",
      "Before: nan nan\n",
      "After: [1, 1]\n",
      "Before: 376 307\n",
      "After: [148, 60]\n",
      "True vocab size: 8786\n",
      "Before: -823 -815 -798 -554 -573 -408 -217 -275 25 -185 105 -467 382 -742 676 -790 756 -839 902 -729 786 -610 109 -731 -337 -582 -224 -183 -153 -207 -263 -422 -254 -387 -112 -447 -39 -737 -112 -909 -105 -872 118 -697 223 -451 39 -269 -40 -57 163 247 324 345 415 230 683 162 1041 118 1277 197 1258 396 941 338 688 245 685 482 489 544 42 236 -172 75 -42 151 243 252 497 245 621 96 818 102 1065 236\n",
      "After: [ 608  545  972  718  758  255   56   95  412  563  128  243  217  670\n",
      "  761  439  483 1082 1088  883  555  751  111  361  582  262  130  119\n",
      "  120  417  527  667   31  166  108  479   52  510  108  992  128 1112\n",
      "  458  485   75  700   52  468  427   78  392  517  182   83  601  552\n",
      "  475  543  769  458 1107  385 1380  386  733   91  940  441  804  219\n",
      "  661  710   29  440   27   73   29  532  160  398  190  441  825  461\n",
      "  936    8 1309  440]\n",
      "Before: -47 2657 693 2790 1605 3661 2135 4000 852 2327 -1193 504 -554 1387 2179 3177 2645 1942 199 -1511 -1776 -2802 -1917 -977 -1691 339 -1662 -568 -707 -553 1018 1709 1341 2230 -162 -613 -1183 -3036 -941 -3377 -1106 -3900 -1681 -4669 -706 -3426 848 -1338 -68 -1817 -1889 -3739 -799 -3316 2195 -824 4466 1315 4999 1747 2567 -252 -578 -2211 -110 -1015 2176 1243 2535 2194 1654 2689 712 2419 487 1648 1725 2307 2492 3611 1387 3751 -495 2412 -2574 67 -3720 -946\n",
      "After: [   6 2343  299 2668 1778 3763 1925 3743  581 2325  942  209  718 1490\n",
      " 2300 3442 2825 2010  282 1334 1911 2590 1757  983 1839   89 1593  278\n",
      "  902  134 1178 1878 1161 2417  543  731 1322 3459  733 3550 1183 3591\n",
      " 1526 4397  794 3228  599 1564   90 1644 2145 3909 1005 2916 2129  962\n",
      " 4261  998 4698 1577 2739  398  256 2443  480  964 2091 1371 2202 2302\n",
      " 1920 2745  298 2533  189 1560 1513 2574 2640 3381 1490 3674  656 2515\n",
      " 2701  442 3806 1111]\n"
     ]
    }
   ],
   "source": [
    "label_vocab_size = 1500 # Don't really need more than 1000, but for some reason a bigger vocab_size is good for the tokenizer\n",
    "label_seq_len = 2\n",
    "\n",
    "features_vocab_size = 15000\n",
    "feature_seq_len = 88\n",
    "\n",
    "def tokenization_processing(x_to_tok, x_val_to_tok, vocab_size=1500, seq_len=2, pad=False):\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=vocab_size,\n",
    "                                       filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                       split=\" \",\n",
    "                                       char_level=False, # Could be very very interesting\n",
    "                                       oov_token=None)\n",
    "\n",
    "    tokenizer.fit_on_texts(x_val_to_tok + x_to_tok)\n",
    "    print('True vocab size:', len(tokenizer.word_index))\n",
    "    \n",
    "    X_tokenized = tokenizer.texts_to_sequences(x_to_tok)\n",
    "    X_val_tokenized = tokenizer.texts_to_sequences(x_val_to_tok)\n",
    "    \n",
    "    if pad:\n",
    "        X_tokenized = pad_sequences(X_tokenized, maxlen=seq_len)\n",
    "        X_val_tokenized = pad_sequences(X_val_tokenized, maxlen=seq_len)\n",
    "    \n",
    "    print('Before:', x_val_to_tok[0])\n",
    "    print('After:', X_val_tokenized[0])\n",
    "    print('Before:', x_to_tok[0])\n",
    "    print('After:',X_tokenized[0])\n",
    "    \n",
    "    return [X_tokenized, X_val_tokenized]\n",
    "\n",
    "Y_tokenized, y_val_tokenized = tokenization_processing(stringified_y, stringified_y_val)\n",
    "X_train_tokenized, X_val_tokenized = tokenization_processing(X_train, X_val, vocab_size=features_vocab_size, seq_len=feature_seq_len, pad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the song (X):  79\n",
      "Length of one second:  250\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the audio data\n",
    "\n",
    "OUTPUTS_PER_SECOND = 20\n",
    "INPUTS_PER_TIMESTEP = 250\n",
    "\n",
    "# Loop over each second of the song and get the audio data for timesteps\n",
    "X = []\n",
    "for ind, i in enumerate(range(0,  len(song_in_map_range), 1000)):\n",
    "    X.append([])\n",
    "    \n",
    "    # Step in timestep frequency, eg 4\n",
    "    for j in range(0, len(song_in_map_range[i:i+1000]), 1000//INPUTS_PER_TIMESTEP):\n",
    "        X[ind].append(song_in_map_range[j].get_array_of_samples())\n",
    "        \n",
    "    # This doesn't work because of the slicing step:\n",
    "    #X.append(song_in_map_range[i:i+1000:1000//INPUTS_PER_TIMESTEP])            \n",
    "    \n",
    "\n",
    "print('Length of the song (X): ', len(X))\n",
    "print('Length of one second: ', len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
